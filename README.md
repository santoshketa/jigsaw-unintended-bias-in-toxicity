# jigsaw-unintended-bias-in-toxicity
# Task of project:Classify given sentence or comment as toxic or non toxic.

The main objective of this project is to remove unintended bias in toxicity caused by same words like white and black, male and female and gay or bisexual etc.

To remove unintended bias caused by some words mentioned above Jigsaw have created custom AUC metric which reduces unintended bias to some extent

I have divided project into two parts 

Part1:EDA and basic ml models.

Part2: Advanced DL models.
